{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "root_dir = '/home/intern/nas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atomic_answer(root_dir):\n",
    "    file_train = os.path.join(root_dir, 'data', 'atomic', 'train_adv-answer.jsonl')\n",
    "    file_dev = os.path.join(root_dir, 'data', 'atomic', 'dev_adv-answer.jsonl')\n",
    "    json_train = pd.read_json(path_or_buf=file_train, lines=True)\n",
    "    json_dev = pd.read_json(path_or_buf=file_dev, lines=True)\n",
    "    train_data = []\n",
    "    train_labels = json_train['correct'].tolist()\n",
    "\n",
    "    for context, candidates, labels in zip(json_train['context'].tolist(), json_train['candidates'].tolist(), json_train['correct'].tolist()):\n",
    "        train_data.append((context, candidates[int(labels)]))\n",
    "    return train_data\n",
    "\n",
    "load_atomic_answer(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_siqa_answersheet(root_dir):\n",
    "    file_path = os.path.join(root_dir, 'data', 'siqa', \"train-predictions.jsonl\")\n",
    "    json_file = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "    context = [elem for elem in zip(json_file['context'].tolist(), json_file['question'].tolist())]\n",
    "    answer_candidate = [cand for cand in zip(json_file['answerA'].tolist(), json_file['answerB'].tolist(), json_file['answerC'].tolist())]\n",
    "    corrects = json_file['correct'].tolist()\n",
    "    correct_to_label = {'A':0, 'B':1, 'C':2}\n",
    "    labels = [correct_to_label[correct] for correct in corrects]\n",
    "    train_data=[]\n",
    "    assert len(context) == len(answer_candidate) == len(labels)\n",
    "    for k in range(len(context)):\n",
    "        answer = answer_candidate[k][labels[k]]\n",
    "        train_data.append((context[k], answer))\n",
    "\n",
    "    \n",
    "    return train_data\n",
    "load_siqa_answersheet(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csqa_answersheet(root_dir):\n",
    "\n",
    "    file_path = os.path.join(root_dir, 'data', 'csqa', 'train.jsonl')\n",
    "    json_file = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "    data = []\n",
    "    answerkeys = json_file['answerKey'].tolist()\n",
    "    print(answerkeys)\n",
    "    answerkey_to_label = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}\n",
    "    labels = [answerkey_to_label[answerkey] for answerkey in answerkeys]\n",
    "    questions = json_file['question'].tolist()\n",
    "    assert len(questions) == len(labels)\n",
    "    idx=0\n",
    "    for sample in json_file['question']:\n",
    "        question = sample['stem']\n",
    "        get_idx = labels[idx]\n",
    "        answer = sample['choices'][get_idx]['text']\n",
    "        data.append((question, answer))\n",
    "        idx+=1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cmqa_answersheet(root_dir):\n",
    "    file_path = os.path.join(root_dir, 'data', 'cmqa', \"train.jsonl\")\n",
    "    json_file = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "    context = [elem for elem in zip(json_file['context'].tolist(), json_file['question'].tolist())]\n",
    "    answer_candidate = [cand for cand in zip(json_file['answer0'].tolist(), json_file['answer1'].tolist(), json_file['answer2'].tolist(), json_file['answer3'].tolist())]\n",
    "    labels = json_file['label'].tolist()\n",
    "    assert len(context) == len(answer_candidate) == len(labels)\n",
    "    train_data=[]\n",
    "    for k in range(len(context)):\n",
    "        answer = answer_candidate[k][labels[k]]\n",
    "        train_data.append((context[k], answer))        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_piqa_answersheet(root_dir):\n",
    "    file_path = os.path.join(root_dir, 'data', 'piqa', 'train.jsonl')\n",
    "    json_file = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "    context = json_file['goal'].tolist()\n",
    "    answer_candidate = [cand for cand in zip(json_file['sol1'].tolist(), json_file['sol2'].tolist())]\n",
    "    labels = json_file['label'].tolist()\n",
    "    assert len(context) == len(answer_candidate) == len(labels)\n",
    "    train_data=[]\n",
    "    for k in range(len(context)):\n",
    "        answer = answer_candidate[k][labels[k]]\n",
    "        train_data.append((context[k], answer))        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderDataset(Dataset):\n",
    "    def __init__(self, tokenizer, input):\n",
    "        self.roberta_tokenizer = tokenizer\n",
    "        self.input = input\n",
    "        self.context_tokenized=[]\n",
    "        self.answer_tokenized=[]\n",
    "        for idx in self.input:\n",
    "            context = idx[0]\n",
    "            answer = idx[1]\n",
    "            encoded_context = self.roberta_tokenizer(context, padding=True, truncation=True, return_tensors='pt')\n",
    "            encoded_answer = self.roberta_tokenizer(answer, padding=True, truncation=True, return_tensors='pt')\n",
    "            self.context_tokenized.append(encoded_context)\n",
    "            self.answer_tokenized.append(encoded_answer)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.context_tokenized[idx], self.answer_tokenized[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biencoder_batch(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    contexts, answers = zip(*batch)\n",
    "\n",
    "    input_ids_context=[]\n",
    "    attention_mask_context=[]\n",
    "    max_len_for_context=0\n",
    "    for context in contexts:\n",
    "        input_ids_context.append(context['input_ids'][0])\n",
    "        attention_mask_context.append(context['attention_mask'][0])\n",
    "        if context['input_ids'][0].shape[0] > max_len_for_context:\n",
    "            max_len_for_context = context['input_ids'][0].shape[0]\n",
    "\n",
    "    input_ids_answer=[]\n",
    "    attention_mask_answer=[]\n",
    "    max_len_for_answer=0\n",
    "    for answer in answers:\n",
    "        input_ids_answer.append(answer['input_ids'][0])\n",
    "        attention_mask_answer.append(answer['attention_mask'][0])\n",
    "        if answer['input_ids'][0].shape[0] > max_len_for_answer:\n",
    "            max_len_for_answer = answer['input_ids'][0].shape[0]\n",
    "\n",
    "    padded_input_ids_context=[]\n",
    "    padded_input_ids_answer=[]\n",
    "    padded_attention_mask_context=[]\n",
    "    padded_attention_mask_answer=[]\n",
    "    for input_ids, attention_mask in zip(input_ids_context, attention_mask_context):\n",
    "        padding_len = max_len_for_context - input_ids.shape[0]\n",
    "        if padding_len > 0:\n",
    "            padded_input_ids = torch.cat([input_ids, torch.LongTensor([0] * padding_len)])\n",
    "            padded_attention_mask = torch.cat([attention_mask, torch.LongTensor([0] * padding_len)])\n",
    "            padded_input_ids_context.append(padded_input_ids)\n",
    "            padded_attention_mask_context.append(padded_attention_mask)            \n",
    "        else:\n",
    "            padded_input_ids_context.append(input_ids)\n",
    "            padded_attention_mask_context.append(attention_mask)\n",
    "\n",
    "    for input_ids, attention_mask in zip(input_ids_answer, attention_mask_answer):\n",
    "        padding_len = max_len_for_answer - input_ids.shape[0]\n",
    "        if padding_len > 0:\n",
    "            padded_input_ids = torch.cat([input_ids, torch.LongTensor([0] * padding_len)])\n",
    "            padded_attention_mask = torch.cat([attention_mask, torch.LongTensor([0] * padding_len)])\n",
    "            padded_input_ids_answer.append(padded_input_ids)\n",
    "            padded_attention_mask_answer.append(padded_attention_mask)            \n",
    "        else:\n",
    "            padded_input_ids_answer.append(input_ids)\n",
    "            padded_attention_mask_answer.append(attention_mask)\n",
    "            \n",
    "    \n",
    "\n",
    "    batch = (torch.stack(padded_input_ids_context), torch.stack(padded_input_ids_answer), torch.stack(padded_attention_mask_context), torch.stack(padded_attention_mask_answer))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 9000 Valid Set: 7113\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import BiEncoder\n",
    "from utils import Trainer\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "root_dir = '/home/intern/nas'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "train_data = load_piqa_answersheet(root_dir)\n",
    "train_data, valid_data = train_test_split(train_data, train_size=9000, random_state=42)\n",
    "train_dataset = BiEncoderDataset(tokenizer, train_data)\n",
    "valid_dataset = BiEncoderDataset(tokenizer, valid_data)\n",
    "print('Train Set:', len(train_dataset), 'Valid Set:', len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda batch: biencoder_batch(batch))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=True, collate_fn=lambda batch: biencoder_batch(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self, context_bert_model, response_bert_model):\n",
    "        super(BiEncoder, self).__init__()\n",
    "        self.context_bert = context_bert_model\n",
    "        self.response_bert = response_bert_model\n",
    "    def forward(self, context_input_ids, context_input_masks,\n",
    "                            responses_input_ids, responses_input_masks, labels=None):\n",
    "\n",
    "        context = self.context_bert(input_ids = context_input_ids, attention_mask = context_input_masks)\n",
    "\n",
    "        # print(output[1])\n",
    "\n",
    "        response = self.response_bert(input_ids = responses_input_ids, attention_mask = responses_input_masks)\n",
    "\n",
    "        context_vector = context[1]\n",
    "        response_vector = response[1]\n",
    "        dot_product = torch.matmul(context_vector, response_vector.t())  # [bs, bs]\n",
    "        mask = torch.eye(context_input_ids.size(0)).to(context_input_ids.device)\n",
    "        loss = F.log_softmax(dot_product, dim=-1) * mask\n",
    "        loss = (-loss.sum(dim=1)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 21])\n",
      "torch.Size([8, 73])\n",
      "tensor([[ 0.1550,  0.7119,  0.4564,  ...,  0.0052,  0.4077, -0.3467],\n",
      "        [ 0.1492,  0.7084,  0.4518,  ...,  0.0020,  0.4129, -0.3730],\n",
      "        [ 0.1643,  0.7136,  0.4519,  ..., -0.0219,  0.4205, -0.3409],\n",
      "        ...,\n",
      "        [ 0.1597,  0.7124,  0.4698,  ...,  0.0025,  0.3666, -0.3821],\n",
      "        [ 0.1541,  0.7165,  0.4280,  ..., -0.0080,  0.4142, -0.3530],\n",
      "        [ 0.1356,  0.6615,  0.5050,  ..., -0.0038,  0.3687, -0.3477]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 20])\n",
      "torch.Size([8, 30])\n",
      "tensor([[ 0.1292,  0.6961,  0.4832,  ..., -0.0157,  0.4267, -0.3728],\n",
      "        [ 0.1586,  0.7525,  0.3766,  ...,  0.1652,  0.2875, -0.1965],\n",
      "        [ 0.1355,  0.6739,  0.4920,  ...,  0.0075,  0.3658, -0.3775],\n",
      "        ...,\n",
      "        [ 0.1311,  0.6977,  0.4685,  ..., -0.0158,  0.4219, -0.3668],\n",
      "        [ 0.1211,  0.7507,  0.3568,  ...,  0.1454,  0.3151, -0.1933],\n",
      "        [ 0.1690,  0.7148,  0.4312,  ...,  0.0196,  0.4032, -0.3274]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 18])\n",
      "torch.Size([8, 28])\n",
      "tensor([[ 0.1455,  0.7164,  0.4805,  ...,  0.0052,  0.4237, -0.3358],\n",
      "        [ 0.1642,  0.6715,  0.4906,  ...,  0.0264,  0.4015, -0.3893],\n",
      "        [ 0.1445,  0.6797,  0.4780,  ...,  0.0067,  0.3702, -0.4019],\n",
      "        ...,\n",
      "        [ 0.0310,  0.7201,  0.3220,  ...,  0.2555,  0.1351, -0.0815],\n",
      "        [ 0.1303,  0.6968,  0.4773,  ..., -0.0243,  0.4231, -0.3520],\n",
      "        [ 0.1556,  0.6725,  0.4942,  ...,  0.0277,  0.3459, -0.4113]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8, 37])\n",
      "tensor([[ 0.1335,  0.7346,  0.3397,  ...,  0.1539,  0.3019, -0.2144],\n",
      "        [ 0.1592,  0.7073,  0.4505,  ...,  0.0027,  0.4200, -0.3607],\n",
      "        [ 0.1699,  0.7137,  0.4377,  ..., -0.0045,  0.3852, -0.3858],\n",
      "        ...,\n",
      "        [ 0.1422,  0.7280,  0.3806,  ...,  0.1620,  0.2998, -0.1879],\n",
      "        [ 0.1328,  0.7410,  0.3354,  ...,  0.1647,  0.2908, -0.2255],\n",
      "        [ 0.0514,  0.6929,  0.4864,  ..., -0.0197,  0.3949, -0.4031]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 21])\n",
      "torch.Size([8, 220])\n",
      "tensor([[ 0.1369,  0.7061,  0.4520,  ..., -0.0075,  0.3592, -0.3601],\n",
      "        [ 0.1327,  0.6824,  0.4579,  ..., -0.0346,  0.3412, -0.3818],\n",
      "        [ 0.1416,  0.6911,  0.4703,  ..., -0.0141,  0.3844, -0.3812],\n",
      "        ...,\n",
      "        [ 0.1691,  0.7153,  0.4612,  ...,  0.0119,  0.4013, -0.3769],\n",
      "        [ 0.1171,  0.7484,  0.3540,  ...,  0.1376,  0.3282, -0.2206],\n",
      "        [ 0.1616,  0.7073,  0.4512,  ...,  0.0015,  0.4065, -0.3538]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 28])\n",
      "tensor([[ 0.1871,  0.7101,  0.4632,  ...,  0.0016,  0.4037, -0.3830],\n",
      "        [ 0.1582,  0.7076,  0.4645,  ..., -0.0150,  0.4091, -0.3656],\n",
      "        [ 0.1687,  0.7136,  0.4496,  ...,  0.0134,  0.4172, -0.3607],\n",
      "        ...,\n",
      "        [ 0.1122,  0.7391,  0.3830,  ...,  0.1325,  0.3254, -0.2118],\n",
      "        [ 0.1477,  0.6870,  0.4730,  ...,  0.0304,  0.3441, -0.3835],\n",
      "        [ 0.1384,  0.7005,  0.4637,  ...,  0.0041,  0.3799, -0.3893]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8, 109])\n",
      "tensor([[ 0.1569,  0.7121,  0.4348,  ..., -0.0130,  0.3989, -0.3510],\n",
      "        [ 0.1389,  0.6776,  0.4823,  ..., -0.0077,  0.3622, -0.3790],\n",
      "        [ 0.1303,  0.7313,  0.3612,  ...,  0.1666,  0.2552, -0.2216],\n",
      "        ...,\n",
      "        [ 0.1693,  0.7079,  0.4274,  ...,  0.0082,  0.4000, -0.3442],\n",
      "        [ 0.1484,  0.7167,  0.4285,  ..., -0.0013,  0.3918, -0.3839],\n",
      "        [ 0.1275,  0.7401,  0.3766,  ...,  0.1704,  0.2759, -0.1904]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 23])\n",
      "torch.Size([8, 93])\n",
      "tensor([[ 0.1250,  0.7545,  0.3527,  ...,  0.1662,  0.3269, -0.2284],\n",
      "        [ 0.1533,  0.7112,  0.5093,  ..., -0.0020,  0.4058, -0.4019],\n",
      "        [ 0.1225,  0.7507,  0.3829,  ...,  0.1359,  0.3247, -0.1794],\n",
      "        ...,\n",
      "        [ 0.1745,  0.7070,  0.4925,  ...,  0.0303,  0.3558, -0.3932],\n",
      "        [ 0.1283,  0.6754,  0.4943,  ..., -0.0277,  0.3681, -0.3961],\n",
      "        [ 0.1833,  0.7121,  0.4442,  ..., -0.0039,  0.4134, -0.3587]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 15])\n",
      "torch.Size([8, 57])\n",
      "tensor([[ 0.1050,  0.6920,  0.4842,  ..., -0.0317,  0.3591, -0.3763],\n",
      "        [ 0.1444,  0.6967,  0.4851,  ...,  0.0255,  0.3795, -0.4040],\n",
      "        [ 0.1390,  0.7088,  0.4772,  ..., -0.0144,  0.4163, -0.3637],\n",
      "        ...,\n",
      "        [ 0.1109,  0.7410,  0.3723,  ...,  0.1019,  0.3265, -0.1837],\n",
      "        [ 0.1695,  0.7090,  0.4562,  ...,  0.0037,  0.4026, -0.3702],\n",
      "        [ 0.1668,  0.6963,  0.4504,  ..., -0.0134,  0.3878, -0.3689]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 21])\n",
      "torch.Size([8, 85])\n",
      "tensor([[ 0.1878,  0.7079,  0.4431,  ..., -0.0181,  0.3984, -0.3878],\n",
      "        [ 0.1541,  0.7174,  0.4551,  ...,  0.0113,  0.4011, -0.3699],\n",
      "        [ 0.1593,  0.7052,  0.4721,  ..., -0.0281,  0.3869, -0.3816],\n",
      "        ...,\n",
      "        [ 0.1755,  0.7122,  0.4372,  ...,  0.0086,  0.4066, -0.3768],\n",
      "        [ 0.1731,  0.7103,  0.4439,  ..., -0.0085,  0.4135, -0.3957],\n",
      "        [ 0.1720,  0.7049,  0.4368,  ..., -0.0054,  0.3795, -0.3706]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 18])\n",
      "torch.Size([8, 63])\n",
      "tensor([[ 0.0884,  0.7403,  0.3827,  ...,  0.1680,  0.3279, -0.2243],\n",
      "        [ 0.1395,  0.6878,  0.4607,  ..., -0.0012,  0.3573, -0.3719],\n",
      "        [ 0.1744,  0.7134,  0.4458,  ..., -0.0075,  0.4292, -0.3572],\n",
      "        ...,\n",
      "        [ 0.1670,  0.6919,  0.4740,  ..., -0.0179,  0.3576, -0.3765],\n",
      "        [ 0.1013,  0.7411,  0.3323,  ...,  0.2106,  0.2486, -0.1593],\n",
      "        [ 0.1405,  0.6861,  0.4884,  ..., -0.0117,  0.3668, -0.3944]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 11])\n",
      "torch.Size([8, 72])\n",
      "tensor([[ 1.1239e-01,  7.5534e-01,  3.7955e-01,  ...,  1.0415e-01,\n",
      "          3.0341e-01, -2.1555e-01],\n",
      "        [ 1.6306e-01,  7.2027e-01,  4.4148e-01,  ...,  1.8426e-04,\n",
      "          3.9080e-01, -3.8395e-01],\n",
      "        [ 1.1380e-01,  6.9961e-01,  4.7838e-01,  ..., -2.0793e-02,\n",
      "          4.0385e-01, -3.7676e-01],\n",
      "        ...,\n",
      "        [ 1.3292e-01,  6.9554e-01,  4.6152e-01,  ..., -1.3532e-02,\n",
      "          3.5503e-01, -3.9119e-01],\n",
      "        [ 1.6843e-01,  7.1459e-01,  4.5122e-01,  ..., -1.1640e-02,\n",
      "          3.9512e-01, -3.8193e-01],\n",
      "        [ 1.7004e-01,  7.1129e-01,  4.4535e-01,  ...,  6.8602e-03,\n",
      "          4.1186e-01, -3.8371e-01]], grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8, 75])\n",
      "tensor([[ 0.0940,  0.7482,  0.3586,  ...,  0.1782,  0.2992, -0.1731],\n",
      "        [ 0.1695,  0.7095,  0.4493,  ...,  0.0109,  0.4115, -0.3591],\n",
      "        [ 0.1389,  0.7015,  0.4561,  ...,  0.0151,  0.4055, -0.3565],\n",
      "        ...,\n",
      "        [ 0.1235,  0.7357,  0.3502,  ...,  0.1559,  0.2590, -0.2268],\n",
      "        [ 0.1333,  0.6830,  0.4704,  ...,  0.0013,  0.3589, -0.3954],\n",
      "        [ 0.1019,  0.7423,  0.3635,  ...,  0.1485,  0.3122, -0.1860]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 21])\n",
      "torch.Size([8, 68])\n",
      "tensor([[ 0.1951,  0.7148,  0.4482,  ...,  0.0085,  0.3849, -0.3684],\n",
      "        [ 0.1055,  0.7512,  0.3183,  ...,  0.1420,  0.2929, -0.1867],\n",
      "        [ 0.1005,  0.7388,  0.3511,  ...,  0.1714,  0.2871, -0.1948],\n",
      "        ...,\n",
      "        [ 0.1444,  0.6951,  0.4892,  ..., -0.0103,  0.3728, -0.3860],\n",
      "        [ 0.1567,  0.6939,  0.4925,  ...,  0.0115,  0.3926, -0.4090],\n",
      "        [ 0.1637,  0.7178,  0.4678,  ..., -0.0220,  0.4009, -0.3419]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 23])\n",
      "torch.Size([8, 39])\n",
      "tensor([[ 0.1324,  0.7476,  0.3777,  ...,  0.1138,  0.2850, -0.2076],\n",
      "        [ 0.0845,  0.7433,  0.3812,  ...,  0.1687,  0.2992, -0.2015],\n",
      "        [ 0.1751,  0.7189,  0.4646,  ...,  0.0214,  0.4028, -0.3437],\n",
      "        ...,\n",
      "        [ 0.1664,  0.7125,  0.4412,  ...,  0.0116,  0.3880, -0.3579],\n",
      "        [ 0.1673,  0.7051,  0.4555,  ...,  0.0161,  0.4099, -0.3699],\n",
      "        [ 0.1478,  0.6904,  0.4782,  ..., -0.0256,  0.3955, -0.3708]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8, 46])\n",
      "tensor([[ 0.1624,  0.7236,  0.4471,  ...,  0.0193,  0.4295, -0.3607],\n",
      "        [ 0.1224,  0.6991,  0.4908,  ..., -0.0084,  0.4219, -0.3584],\n",
      "        [ 0.1448,  0.6926,  0.4636,  ..., -0.0064,  0.4227, -0.3751],\n",
      "        ...,\n",
      "        [ 0.1277,  0.6792,  0.4995,  ..., -0.0201,  0.3730, -0.3842],\n",
      "        [ 0.1277,  0.6880,  0.4978,  ..., -0.0290,  0.3581, -0.3824],\n",
      "        [ 0.1502,  0.7182,  0.4617,  ..., -0.0109,  0.3933, -0.3788]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 13])\n",
      "torch.Size([8, 76])\n",
      "tensor([[ 1.5832e-01,  6.9841e-01,  4.5826e-01,  ..., -3.8860e-03,\n",
      "          4.1697e-01, -3.5184e-01],\n",
      "        [ 1.1935e-01,  7.3536e-01,  3.4941e-01,  ...,  1.2114e-01,\n",
      "          3.0707e-01, -2.0062e-01],\n",
      "        [ 1.1385e-01,  6.6784e-01,  4.8441e-01,  ...,  1.5875e-02,\n",
      "          3.4737e-01, -4.0828e-01],\n",
      "        ...,\n",
      "        [ 1.6728e-01,  7.1266e-01,  4.4205e-01,  ...,  4.5375e-04,\n",
      "          4.0192e-01, -3.8934e-01],\n",
      "        [ 1.1921e-01,  7.5674e-01,  3.8151e-01,  ...,  1.5086e-01,\n",
      "          3.0010e-01, -2.1860e-01],\n",
      "        [ 1.0788e-01,  7.5977e-01,  3.7377e-01,  ...,  1.5762e-01,\n",
      "          2.7517e-01, -2.1576e-01]], grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8, 35])\n",
      "tensor([[ 0.0788,  0.7232,  0.3702,  ...,  0.1552,  0.3145, -0.1984],\n",
      "        [ 0.1700,  0.7168,  0.4472,  ..., -0.0081,  0.4442, -0.3669],\n",
      "        [ 0.1546,  0.7096,  0.4586,  ..., -0.0056,  0.3878, -0.3695],\n",
      "        ...,\n",
      "        [ 0.1557,  0.7127,  0.4630,  ..., -0.0016,  0.4157, -0.3843],\n",
      "        [ 0.1602,  0.7072,  0.4633,  ..., -0.0150,  0.3780, -0.3812],\n",
      "        [ 0.1225,  0.6722,  0.4787,  ..., -0.0530,  0.3641, -0.3985]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 18])\n",
      "torch.Size([8, 48])\n",
      "tensor([[ 0.1669,  0.7052,  0.4304,  ...,  0.0110,  0.3855, -0.3855],\n",
      "        [ 0.1463,  0.6618,  0.5011,  ..., -0.0062,  0.3533, -0.3863],\n",
      "        [ 0.1769,  0.7066,  0.4457,  ..., -0.0024,  0.4138, -0.3344],\n",
      "        ...,\n",
      "        [ 0.1705,  0.7022,  0.4540,  ...,  0.0193,  0.4159, -0.3776],\n",
      "        [ 0.1721,  0.7063,  0.4511,  ..., -0.0231,  0.4123, -0.3543],\n",
      "        [ 0.1500,  0.6906,  0.4837,  ..., -0.0173,  0.4073, -0.4073]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 13])\n",
      "torch.Size([8, 28])\n",
      "tensor([[ 0.1704,  0.6997,  0.4247,  ..., -0.0026,  0.4034, -0.3535],\n",
      "        [ 0.1555,  0.7168,  0.4447,  ...,  0.0149,  0.3927, -0.3641],\n",
      "        [ 0.1394,  0.6999,  0.4763,  ..., -0.0057,  0.4138, -0.3737],\n",
      "        ...,\n",
      "        [ 0.1753,  0.6992,  0.4534,  ...,  0.0286,  0.3522, -0.4113],\n",
      "        [ 0.1312,  0.6956,  0.4792,  ..., -0.0174,  0.4161, -0.3740],\n",
      "        [ 0.1183,  0.7359,  0.3672,  ...,  0.1448,  0.3007, -0.1797]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8, 59])\n",
      "tensor([[ 0.1313,  0.7563,  0.3653,  ...,  0.0915,  0.3180, -0.1600],\n",
      "        [ 0.1163,  0.7518,  0.3784,  ...,  0.1524,  0.3267, -0.1988],\n",
      "        [ 0.1717,  0.7142,  0.4504,  ...,  0.0056,  0.4004, -0.3574],\n",
      "        ...,\n",
      "        [ 0.1563,  0.7193,  0.4219,  ...,  0.0041,  0.4172, -0.3550],\n",
      "        [ 0.1336,  0.6903,  0.4726,  ..., -0.0086,  0.3759, -0.3719],\n",
      "        [ 0.1179,  0.7440,  0.3659,  ...,  0.1478,  0.3047, -0.2081]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 17])\n",
      "torch.Size([8, 82])\n",
      "tensor([[ 0.1641,  0.7176,  0.4562,  ...,  0.0009,  0.4097, -0.3634],\n",
      "        [ 0.1521,  0.6883,  0.4836,  ..., -0.0354,  0.3870, -0.3718],\n",
      "        [ 0.1043,  0.7434,  0.3836,  ...,  0.1902,  0.3031, -0.2021],\n",
      "        ...,\n",
      "        [ 0.1539,  0.7107,  0.4648,  ...,  0.0036,  0.3753, -0.3720],\n",
      "        [ 0.1797,  0.7219,  0.4406,  ...,  0.0072,  0.3922, -0.3636],\n",
      "        [ 0.1164,  0.7540,  0.3391,  ...,  0.1489,  0.2936, -0.1978]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 14])\n",
      "torch.Size([8, 160])\n",
      "tensor([[ 0.1562,  0.7111,  0.4464,  ...,  0.0103,  0.4034, -0.3719],\n",
      "        [ 0.1784,  0.7115,  0.4694,  ..., -0.0093,  0.4159, -0.3607],\n",
      "        [ 0.1583,  0.6867,  0.4952,  ...,  0.0191,  0.3566, -0.3822],\n",
      "        ...,\n",
      "        [ 0.1575,  0.6900,  0.4559,  ...,  0.0029,  0.3960, -0.4007],\n",
      "        [ 0.1167,  0.7095,  0.4638,  ..., -0.0158,  0.4356, -0.3437],\n",
      "        [ 0.1440,  0.6985,  0.4824,  ..., -0.0013,  0.3741, -0.3829]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8, 302])\n",
      "tensor([[ 0.1665,  0.7228,  0.4636,  ...,  0.0173,  0.4093, -0.3671],\n",
      "        [ 0.1496,  0.6798,  0.4892,  ..., -0.0458,  0.3520, -0.3934],\n",
      "        [ 0.1046,  0.7423,  0.3648,  ...,  0.1499,  0.3091, -0.2263],\n",
      "        ...,\n",
      "        [ 0.1268,  0.7338,  0.3510,  ...,  0.1397,  0.3079, -0.2076],\n",
      "        [ 0.1612,  0.6951,  0.4840,  ..., -0.0022,  0.3791, -0.3521],\n",
      "        [ 0.1191,  0.6896,  0.4896,  ..., -0.0520,  0.3730, -0.3910]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 14])\n",
      "torch.Size([8, 77])\n",
      "tensor([[ 1.7775e-01,  7.1350e-01,  4.6062e-01,  ...,  2.6653e-04,\n",
      "          3.9895e-01, -3.7578e-01],\n",
      "        [ 1.3808e-01,  7.0505e-01,  4.6639e-01,  ..., -2.5883e-02,\n",
      "          4.1564e-01, -3.5322e-01],\n",
      "        [ 9.2799e-02,  7.3440e-01,  3.5348e-01,  ...,  1.6615e-01,\n",
      "          2.9091e-01, -2.1626e-01],\n",
      "        ...,\n",
      "        [ 1.6337e-01,  7.2131e-01,  4.5589e-01,  ..., -1.0085e-02,\n",
      "          4.0151e-01, -3.7979e-01],\n",
      "        [ 1.5040e-01,  7.1163e-01,  4.5813e-01,  ...,  2.8707e-03,\n",
      "          4.1012e-01, -3.5295e-01],\n",
      "        [ 1.4669e-01,  6.9967e-01,  4.7947e-01,  ..., -2.7129e-02,\n",
      "          4.1800e-01, -3.7462e-01]], grad_fn=<TanhBackward>)\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 1024])\n",
      "torch.Size([8, 13])\n",
      "torch.Size([8, 45])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46337/355814917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     output = model(context_input_ids=input_ids_context, context_input_masks = attention_mask_context,\n\u001b[1;32m      8\u001b[0m                     \u001b[0mresponses_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses_input_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     labels=None)\n\u001b[0m",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46337/3898918573.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context_input_ids, context_input_masks, responses_input_ids, responses_input_masks, labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m## only select the first response (whose lbl==1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_input_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         )\n\u001b[1;32m    419\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/miniconda3/envs/seungjun/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roberta_model_1 = RobertaModel.from_pretrained('roberta-large')\n",
    "roberta_model_2 = RobertaModel.from_pretrained('roberta-large')\n",
    "model = BiEncoder(roberta_model_1, roberta_model_2)\n",
    "\n",
    "for batch in train_loader:\n",
    "    input_ids_context, input_ids_answer, attention_mask_context, attention_mask_answer =batch\n",
    "    output = model(context_input_ids=input_ids_context, context_input_masks = attention_mask_context,\n",
    "                    responses_input_ids=input_ids_answer, responses_input_masks=attention_mask_answer,\n",
    "                    labels=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46337/3747332261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6]]\n",
    "b = torch.stack(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d585f5dd46ff142a1cbe6d0513d2e0a6b200deb517a60b6f75be1b97d8951e6e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('seungjun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
