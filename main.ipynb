{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import RobertaTokenizer, AdamW, RobertaModel\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from dataset import load_piqa, load_siqa, load_csqa, load_cmqa, load_piqa\n",
    "from dataset import SocialiqaDataset, CommonsenseqaDataset, CosmosqaDataset, PhysicaliqaDataset\n",
    "from model import Multiple_Choice_Model\n",
    "from utils import get_best_model, test\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def parser_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--cur_dir', type=str, default='/home/chaehyeong/CKL')\n",
    "    parser.add_argument('--root_dir', type=str, default='/home/chaehyeong/nas')\n",
    "\n",
    "    parser.add_argument('--lm', type=str, required=True, choices=['roberta-large', 'roberta-cskg'], help='Pre-trained LM or KG fine-tuned LM')\n",
    "    parser.add_argument('--pre_task', type=str, default=None)\n",
    "    parser.add_argument('--cur_task', type=str, required=True, choices=['siqa', 'csqa', 'cmqa', 'piqa'])\n",
    "    parser.add_argument('--training_size', type=float, required=True, help='Training data size for fine-tuning LM')\n",
    "    parser.add_argument('--target_task', type=str, required=True, choices=['siqa', 'csqa', 'cmqa', 'piqa'], help='Which QA dataset to use for evaluating LM')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, required=True)\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# dataset and dataloader\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_siqa_copy(root_dir, mode):\n",
    "    if mode == 'train':\n",
    "        file_path = os.path.join(root_dir, 'data', 'siqa', \"train-predictions.jsonl\")\n",
    "    elif mode == 'dev':\n",
    "        file_path = os.path.join(root_dir, 'data', 'siqa', \"dev-predictions.jsonl\")\n",
    "    json_file = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "    data = [elem for elem in zip(json_file['context'].tolist(), json_file['question'].tolist(), json_file['answerA'].tolist(), json_file['answerB'].tolist(), json_file['answerC'].tolist())]\n",
    "    corrects = json_file['correct'].tolist()\n",
    "\n",
    "    correct_to_label = {'A':0, 'B':1, 'C':2}\n",
    "    labels = [correct_to_label[correct] for correct in corrects]\n",
    "\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Tracy didn't go home that evening and resisted Riley's attacks.\", 'What does Tracy need to do before this?', 'make a new plan', 'Go home and see Riley', 'Find somewhere to go')\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Answer A', 'Answer B', 'Answer C']\n",
    "test_texts, test_labels = load_siqa_copy('/home/intern/nas', 'dev')\n",
    "print(test_texts[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialiqaDataset_copy(Dataset):\n",
    "    def __init__(self, tokenizer, x, y):\n",
    "        # x: list of tuples containing (context, question, answer1, answer2, answer3)\n",
    "        # y: list of indices of the correct answer\n",
    "        self.roberta_tokenizer = tokenizer\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.x_tokenized = []\n",
    "        for point in self.x:\n",
    "            input_answers = [point[2], point[3], point[4]]\n",
    "            num_choices = len(input_answers)\n",
    "            input_context_question = [point[0] + self.roberta_tokenizer.sep_token + point[1]] * num_choices\n",
    "            encoded_text_train = self.roberta_tokenizer(input_context_question, input_answers, padding=True, return_tensors='pt')\n",
    "            self.x_tokenized.append(encoded_text_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x_tokenized[idx], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d585f5dd46ff142a1cbe6d0513d2e0a6b200deb517a60b6f75be1b97d8951e6e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('seungjun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
